# kube-aws config
#    https://kubernetes-incubator.github.io/kube-aws/
#    https://github.com/kubernetes-incubator/kube-aws/blob/master/core/controlplane/config/templates/cluster.yaml
#
# Unique name of Kubernetes cluster. In order to deploy
# more than one cluster into the same AWS account, this
# name must not conflict with an existing cluster.
clusterName: ${cluster_name}

# DNS name routable to the Kubernetes controller nodes
# from worker nodes and external clients. Configure the options
# below if you would like kube-aws to create a Route53 record sets/hosted zones
# for you.  Otherwise the deployer is responsible for making this name routable
#externalDNSName: controller.internal.io

apiEndpoints: 
- # The unique name of this API endpoint used to identify it inside CloudFormation stacks or
  name: ${cluster_name}
  dnsName: k8s-${cluster_name}.internal.io
  loadBalancer:
    subnets:
      - name: private
    private: true
    hostedZone:
      id: ${hosted_zone}

keyName: ${key_name}
sshAuthorizedKeys:
${kube_additional_keys}

region: "${aws_region}"
kmsKeyArn: "${kms_key}"

controller:
  autoScalingGroup: 
    minSize: 1
    maxSize: 3
    rollingUpdateMinInstancesInService: 2
  subnets:
    - name: private

worker:
  nodePools:
    - # Name of this node pool. Must be unique among all the node pools in this cluster
      name: nodepool
      subnets:
        - name: private
      iam:
        role:
          name: ${cluster_name}
          managedPolicies:
            - arn: "arn:aws:iam::aws:policy/CloudWatchLogsFullAccess"
      autoScalingGroup:
        minSize: 1
        maxSize: 10
        rollingUpdateMinInstancesInService: 2
      autoscaling:
        clusterAutoscaler:
          enabled: true


etcd:
  count: 3
  dataVolume:
    encrypted: true
  subnets:
  - name: private
  memberIdentityProvider: eni

vpc:
  id: ${vpc_id}
  routeTableId: ${route_table_id}

useCalico: true

# CIDR for Kubernetes subnet when placing nodes in a single availability zone (not highly-available) Leave commented out for multi availability zone setting and use the below `subnets` section instead.
# instanceCIDR: "10.0.0.0/24"
subnets:
  - name: private
    id: "${subnet_id}"
    #private: true
    availabilityZone: "${subnet_zone}"
    instanceCIDR: "${subnet_cidr}"
    securityGroupIds:
      - ${security_group_id}
    mapPublicIPs: false


addons:
  clusterAutoscaler:
    enabled: true


# CIDR for Kubernetes subnet when placing nodes in a single availability zone (not highly-available) Leave commented out for multi availability zone setting and use the below `subnets` section instead.
# instanceCIDR: "10.0.0.0/24"
subnets:
  - name: private
    #private: true
    id: "${subnet_id}"
    instanceCIDR: "${subnet_cidr}"
    availabilityZone: "${subnet_zone}"
    securityGroupIds:
      - ${security_group_id}


stackTags:
  Environment: ${cluster_name}
  Organization: "Basic Service"
